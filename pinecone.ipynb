{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU pinecone-client==3.0.0  pinecone-datasets==0.7.0  langchain-pinecone==0.0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suyash Agarwal\\Desktop\\internshala\\intellify\\.conda\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"Big Mac Index.pdf\") # change document Here\n",
    "pages = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "embeddings=OpenAIEmbeddings() # open ai emebeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "index_name = \"question-maker-rag\"\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "retriever = docsearch.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# Prompt from https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chains/qa_generation\n",
    "template = \"\"\"You are a smart assistant designed to help high school teachers come up with reading comprehension questions.\n",
    "Given a piece of context, you must come up with a question and answer pair that can be used to test a student's reading comprehension abilities.\n",
    "When coming up with this question/answer pair\n",
    "\n",
    "Please come up with a question/answer pair, in JSON format, for the following context:\n",
    "----------------\n",
    "{context}\n",
    "\n",
    "The User will specify how many and what type of questions it wants by {question}\n",
    "\n",
    "The type of questions can be of  three categories: \n",
    "1.True or False \n",
    "2.Multiple Choice Questions (MCQs)\n",
    "3.one-word answers.\n",
    "\n",
    "Specify the type of each question as\n",
    "1.True or False = True/False\n",
    "2.Multiple Choice Questions (MCQs) = MCQs\n",
    "3.one-word answers. = one-word answer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# simple RAG\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever , \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# invoking the chain with number of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of question of each type to generate\n",
    "mcq=2\n",
    "OneWord =2\n",
    "T_F=2\n",
    "\n",
    "Total = mcq+OneWord+T_F\n",
    "z = f\"Total {Total} questions, {T_F} of which are True or False questions, {mcq} are Multiple Choice Questions (MCQs), and {OneWord} are one-word answer questions.\"\n",
    "\n",
    "ans=rag_chain.invoke(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"questions\": [\\n        {\\n            \"question\": \"True or False: The Big Mac Index is limited by geographical coverage due to the presence of the McDonald\\'s franchise in Africa.\",\\n            \"answer\": \"True\",\\n            \"type\": \"True/False\"\\n        },\\n        {\\n            \"question\": \"True or False: The Big Mac Index is a reliable measurement of purchasing power parity according to all economists.\",\\n            \"answer\": \"False\",\\n            \"type\": \"True/False\"\\n        },\\n        {\\n            \"question\": \"Which country had the most expensive Big Mac in July 2023?\",\\n            \"options\": [\"Switzerland\", \"Norway\", \"Uruguay\", \"Argentina\", \"EU\", \"Sweden\"],\\n            \"answer\": \"Switzerland\",\\n            \"type\": \"MCQs\"\\n        },\\n        {\\n            \"question\": \"In which city did it take the least amount of time to earn enough to buy a Big Mac in July 2015?\",\\n            \"options\": [\"Hong Kong\", \"Luxembourg\", \"Tokyo\", \"ZÃ¼rich\", \"Miami\", \"Geneva\"],\\n            \"answer\": \"Hong Kong\",\\n            \"type\": \"MCQs\"\\n        },\\n        {\\n            \"question\": \"What is the implied exchange rate according to the Big Mac Index for the Swiss franc against the US dollar in July 2023?\",\\n            \"answer\": \"1.20 SFr/USD\",\\n            \"type\": \"one-word answer\"\\n        },\\n        {\\n            \"question\": \"Which country had the cheapest Big Mac in July 2023?\",\\n            \"answer\": \"Taiwan\",\\n            \"type\": \"one-word answer\"\\n        }\\n    ]\\n}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "index= Pinecone(api_key=pinecone_api_key).Index(index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
